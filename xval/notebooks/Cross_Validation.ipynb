{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this notebook is to demonstrate how to use the cross validation library on datasets in order to  achieve accurte results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\l ../../ml.q\n",
    ".ml.loadfile`:init.q\n",
    "\\l graphics.q\n",
    "\\c 15 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading library scripts and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell the functions related to the FRESH library are loaded in the 1st line while preprocessing functions used within the notebook are loaded from the folder mlutils. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is taken from the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" to predict whether a mass of cells is malignant or benign.\n",
    "\n",
    "The diagnosis column is removed from the dataset and used as the target as this is what we will be predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean co..\n",
       "-------------------------------------------------------------------------------------------------..\n",
       "842302      17.99       10.38        122.8          1001      0.1184          0.2776           0...\n",
       "842517      20.57       17.77        132.9          1326      0.08474         0.07864          0...\n",
       "8.43009e+07 19.69       21.25        130            1203      0.1096          0.1599           0...\n",
       "8.43483e+07 11.42       20.38        77.58          386.1     0.1425          0.2839           0...\n",
       "8.43584e+07 20.29       14.34        135.1          1297      0.1003          0.1328           0...\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"The dataset contains 569 patient files\"\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data:(\"FSFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\"; enlist \",\") 0:`:datasets/data.csv\n",
    "targets:select diagnosis from data\n",
    "5#data:delete diagnosis from data\n",
    "\"The dataset contains \",(string count data),\" patient files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding is used on the target data to convert symbols into a numerical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets:exec diagnosis_M from .ml.util.onehot[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we produce polynomial features from our data in order to allow for interactions between terms in the system to also be studied not just the individual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean..\n",
       "-------------------------------------------------------------------------------------------------..\n",
       "17.99       10.38        122.8          1001      0.1184          0.2776           0.3001        ..\n",
       "20.57       17.77        132.9          1326      0.08474         0.07864          0.0869        ..\n",
       "19.69       21.25        130            1203      0.1096          0.1599           0.1974        ..\n",
       "11.42       20.38        77.58          386.1     0.1425          0.2839           0.2414        ..\n",
       "20.29       14.34        135.1          1297      0.1003          0.1328           0.198         ..\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ target classifications should be agnostic of id column\n",
    "5#table:(cols[data]except `id)#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean..\n",
       "-------------------------------------------------------------------------------------------------..\n",
       "17.99       10.38        122.8          1001      0.1184          0.2776           0.3001        ..\n",
       "20.57       17.77        132.9          1326      0.08474         0.07864          0.0869        ..\n",
       "19.69       21.25        130            1203      0.1096          0.1599           0.1974        ..\n",
       "11.42       20.38        77.58          386.1     0.1425          0.2839           0.2414        ..\n",
       "20.29       14.34        135.1          1297      0.1003          0.1328           0.198         ..\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ Add 2nd order polynomial features to the table \n",
    "5#table:table^.ml.util.polytab[table;2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean..\n",
       "-------------------------------------------------------------------------------------------------..\n",
       "0.5210374   0.0226581    0.5459885      0.3637328 0.5937528       0.7920373        0.7031396     ..\n",
       "0.6431445   0.2725736    0.6157833      0.5015907 0.2898799       0.181768         0.2036082     ..\n",
       "0.6014956   0.3902604    0.5957432      0.4494168 0.5143089       0.4310165        0.4625117     ..\n",
       "0.2100904   0.3608387    0.2335015      0.1029056 0.8113208       0.8113613        0.5656045     ..\n",
       "0.6298926   0.1565776    0.6309861      0.4892895 0.4303512       0.3478928        0.4639175     ..\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ complete a standard scaling of the dataset to avoid biases due to order of magnitudes in the data\n",
    "5#table:.ml.util.minmaxscaler[table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain| +`radius_mean`texture_mean`perimeter_mean`area_mean`smoothness_mean`compactness_mean`conc..\n",
      "ytrain| 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0..\n",
      "xtest | +`radius_mean`texture_mean`perimeter_mean`area_mean`smoothness_mean`compactness_mean`conc..\n",
      "ytest | 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0..\n"
     ]
    }
   ],
   "source": [
    "/ complete a train-test split on the data, here we set 20% of data to be in test set\n",
    "show tts:.ml.util.traintestsplit[table;targets;0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential split indices with basic k-fold cross validation: 0.9626374\n",
      "Random split indices with basic k-fold cross validation: 0.9538462\n",
      "Stratified split indices with basic k-fold cross validation: 0.960438\n"
     ]
    }
   ],
   "source": [
    "/ At this point we can run consistency checks on the models being used to classify the tumours as\n",
    "/ malignant or benign using cross validation techniques on the training data\n",
    "xtrain:flip value flip tts`xtrain\n",
    "ytrain:tts`ytrain\n",
    "\n",
    "mdl:.p.import[`sklearn.ensemble][`:RandomForestClassifier][`n_estimators pykw 500]\n",
    "\n",
    "i1:.ml.xval.kfsplit[ytrain;5] / sequentially split data into k folds\n",
    "i2:.ml.xval.kfshuff[ytrain;5] / randomise data and split into k folds\n",
    "i3:.ml.xval.kfstrat[ytrain;5] / stratified data split based on target into k folds\n",
    "\n",
    "-1\"Sequential split indices with basic k-fold cross validation: \",string .ml.xval.kfoldx[xtrain;ytrain;i1;mdl];\n",
    "-1\"Random split indices with basic k-fold cross validation: \",string .ml.xval.kfoldx[xtrain;ytrain;i2;mdl];\n",
    "-1\"Stratified split indices with basic k-fold cross validation: \",string .ml.xval.kfoldx[xtrain;ytrain;i3;mdl];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte-Carlo cross validation with 10 repetitions and training size of 80%: 0.9582418\n",
      "Repeated Stratified cross validation, 5 fold, 5 repetitions: 0.9604667\n",
      "Repeated K-Fold cross validation, 5 fold, 5 repetitions: 0.9630769\n"
     ]
    }
   ],
   "source": [
    "/ Another option is to use repeated forms of cross validation such as monte-carlo cross validation\n",
    "/ or repeated k-fold cross validation. These have the benefit of allowing a user to evaluate the consistency\n",
    "/ and robustness of the models produced\n",
    "\n",
    "-1\"Monte-Carlo cross validation with 10 repetitions and training size of 80%: \",\n",
    " string .ml.xval.mcxval[xtrain;ytrain;0.2;mdl;10];\n",
    "-1\"Repeated Stratified cross validation, 5 fold, 5 repetitions: \",\n",
    " string .ml.xval.repkfstrat[xtrain;ytrain;5;5;mdl];\n",
    "-1\"Repeated K-Fold cross validation, 5 fold, 5 repetitions: \",\n",
    " string .ml.xval.repkfval[xtrain;ytrain;5;5;mdl];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperParameter Grid search, maximum score and best hyperparameter set are as follows: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9670558\n",
       "`n_estimators`criterion`max_depth!(,100;,`entropy;,10)\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ Another alternative is to perform a grid search over possible sets of hyperparameters in order to\n",
    "/ find the optimal model for the dataset in question. This grid search can be completed on the training\n",
    "/ data and the outcomes of it implemented into a model which is then applied to the testing set\n",
    "dict:`n_estimators`criterion`max_depth!(10 50 100 500;`gini`entropy;2 5 10 20 30)\n",
    "mdl2:.p.import[`sklearn.ensemble][`:RandomForestClassifier]\n",
    "-1\"HyperParameter Grid search, maximum score and best hyperparameter set are as follows: \";\n",
    ".ml.xval.gridsearch[xtrain;ytrain;i3;mdl2;dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the 'best model' on the testing set was: 0.9824561\n"
     ]
    }
   ],
   "source": [
    "/ We can now fit this best model on our training set and test how well it generalises to new data\n",
    "bstmdl:.p.import[`sklearn.ensemble][`:RandomForestClassifier][pykwargs `n_estimators`criterion`max_depth!(500;`entropy;10)]\n",
    "bstmdl[`:fit][xtrain;ytrain];\n",
    "-1\"Score for the 'best model' on the testing set was: \",\n",
    " string bstmdl[`:score][flip value flip tts`xtest;tts`ytest]`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`n_estimators`criterion`max_depth!(10;`gini;10)\n",
       "0.9736842\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ The previous two cells can compressed within a fitted grid search procedure\n",
    ".ml.xval.gridsearchfit[flip value flip table;targets;0.2;5;mdl2;dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
