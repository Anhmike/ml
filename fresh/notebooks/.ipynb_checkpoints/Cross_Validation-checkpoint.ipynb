{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this notebook is to demonstrate how to use the cross validation library on datasets in order to  achieve accurte results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~\n"
     ]
    }
   ],
   "source": [
    "\\l ../../ml.q\n",
    ".ml.loadfile`:init.q\n",
    "\\l graphics.q\n",
    "\\c 15 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading library scripts and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell the functions related to the FRESH library are loaded in the 1st line while preprocessing functions used within the notebook are loaded from the folder mlutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       open high low  close volume   openint\n",
       "------------------------------------------------\n",
       "1997.05.16 1.97 1.98 1.71 1.73  14700000 0      \n",
       "1997.05.19 1.76 1.77 1.62 1.71  6106800  0      \n",
       "1997.05.20 1.73 1.75 1.64 1.64  5467200  0      \n",
       "1997.05.21 1.64 1.65 1.38 1.43  18853200 0      \n",
       "1997.05.22 1.44 1.45 1.31 1.4   11776800 0      \n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"This dataset contains stock information for 5170 days.\"\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "date       open high low  close volume  \n",
       "----------------------------------------\n",
       "1997.05.16 1.97 1.98 1.71 1.73  14700000\n",
       "1997.05.19 1.76 1.77 1.62 1.71  6106800 \n",
       "1997.05.20 1.73 1.75 1.64 1.64  5467200 \n",
       "1997.05.21 1.64 1.65 1.38 1.43  18853200\n",
       "1997.05.22 1.44 1.45 1.31 1.4   11776800\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5#amzndaydata:{lower[cols x]xcol x}(\"DFFFFJJ\";enlist \",\")0:`:SampleDatasets/amzn_day.us.txt\n",
    "-1!\"This dataset contains stock information for \",(string count amzndaydata),\" days.\"\n",
    "5#amzndaydata:.ml.util.dropconstant[amzndaydata] / drop columns without variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign extracted features and complete extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are attempting to use rolled table forecasting frames to predict the close price for the next day given extracted features from the previous 10 days. To generate the targets the first 10 days were omitted as these the rolled table frames in this case would be incomplete and as such may skew our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabletargets:10 _amzndaydata\n",
    "targets:tabletargets[`close]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we produce polynomial features from our data in order to allow for interactions between terms in the system to also be studied not just the individual features. The date column is also removed from the data as this is not used as a feature and will not be required given the data will be subject to a sliding window which negates its significance as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open high low  close volume   high_open low_open low_high close_open close_high close_low volume_..\n",
       "-------------------------------------------------------------------------------------------------..\n",
       "1.97 1.98 1.71 1.73  14700000 3.9006    3.3687   3.3858   3.4081     3.4254     2.9583    2.8959e..\n",
       "1.76 1.77 1.62 1.71  6106800  3.1152    2.8512   2.8674   3.0096     3.0267     2.7702    1.07479..\n",
       "1.73 1.75 1.64 1.64  5467200  3.0275    2.8372   2.87     2.8372     2.87       2.6896    9458256..\n",
       "1.64 1.65 1.38 1.43  18853200 2.706     2.2632   2.277    2.3452     2.3595     1.9734    3.09192..\n",
       "1.44 1.45 1.31 1.4   11776800 2.088     1.8864   1.8995   2.016      2.03       1.834     1.69585..\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ Add 2nd order polynomial features to the table \n",
    "table:amzndaydata^.ml.util.polytab[flip 1_flip amzndaydata;2]\n",
    "/ Remove the date column from the data as the rolling of data is independent of this\n",
    "5#table:(1_cols t)#t:table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollcreatefeatures:{[x;fns;n] \n",
    " raze{.ml.fresh.createfeatures[x;`placer;(-1)_cols x;y]}[;fns]each\n",
    " {update placer:last y from x y}[x;]each dropswin[n;til count x]}\n",
    "dropswin:{(-1) _ (x-1) _ swin[x;y]}\n",
    "swin:{[w;s]{1_x,y}\\[w#0;s]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placer| absenergy_open absenergy_high absenergy_low absenergy_close absenergy_volume absenergy_hi..\n",
      "------| -----------------------------------------------------------------------------------------..\n",
      "9     | 26.2488        27.315         22.4808       24.2289         1.146768e+15     74.38126    ..\n",
      "10    | 24.648         25.7355        21.8067       23.5161         9.310284e+14     64.50407    ..\n",
      "11    | 23.8913        24.9435        21.3727       22.7824         8.951354e+14     60.27941    ..\n",
      "12    | 23.0888        24.1011        20.6431       22.1092         8.74734e+14      55.97656    ..\n",
      "13    | 22.4156        23.7502        20.6431       22.4359         5.514669e+14     53.43622    ..\n",
      "14    | 22.6524        24.5718        21.2071       23.2315         4.737263e+14     55.83232    ..\n",
      "15    | 23.4199        25.1855        22.1938       23.8376         2.252638e+14     59.29666    ..\n",
      "16    | 24.0639        25.3871        22.4031       23.8376         1.794141e+14     61.63945    ..\n",
      "17    | 23.9676        25.2575        22.4031       23.8683         1.599003e+14     61.0528     ..\n",
      "18    | 24.0924        25.6084        22.6152       24.1482         1.505034e+14     62.22476    ..\n",
      "..\n",
      "The forecasting frame contains 5160 datapoints.\n"
     ]
    }
   ],
   "source": [
    "/ in this example we look only at features of the data alone with no parameters\n",
    "show tabraw:rollcreatefeatures[table;0b;10]\n",
    "-1\"The forecasting frame contains \",(string count tabraw),\" datapoints.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete feature significance tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completion of the feature extraction algorithm the importance of each of the features can be determined through the statistical tests contained in the .fresh.significantfeatures function. This will reduce the number of features used by the machine learning algorithm in making its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placer| absenergy_open absenergy_high absenergy_low absenergy_close absenergy_volume absenergy_hi..\n",
      "------| -----------------------------------------------------------------------------------------..\n",
      "9     | 26.2488        27.315         22.4808       24.2289         1.146768e+15     74.38126    ..\n",
      "10    | 24.648         25.7355        21.8067       23.5161         9.310284e+14     64.50407    ..\n",
      "11    | 23.8913        24.9435        21.3727       22.7824         8.951354e+14     60.27941    ..\n",
      "12    | 23.0888        24.1011        20.6431       22.1092         8.74734e+14      55.97656    ..\n",
      "13    | 22.4156        23.7502        20.6431       22.4359         5.514669e+14     53.43622    ..\n",
      "14    | 22.6524        24.5718        21.2071       23.2315         4.737263e+14     55.83232    ..\n",
      "15    | 23.4199        25.1855        22.1938       23.8376         2.252638e+14     59.29666    ..\n",
      "16    | 24.0639        25.3871        22.4031       23.8376         1.794141e+14     61.63945    ..\n",
      "17    | 23.9676        25.2575        22.4031       23.8683         1.599003e+14     61.0528     ..\n",
      "18    | 24.0924        25.6084        22.6152       24.1482         1.505034e+14     62.22476    ..\n",
      "..\n",
      "The number of columns in the initial dataset is: 6\n",
      "The number of columns in the unfiltered dataset is: 541\n",
      "The number of columns in the filtered dataset is: 321\n"
     ]
    }
   ],
   "source": [
    "show tabreduced:key[tabraw]!(.ml.fresh.significantfeatures[p;targets])#p:value tabraw\n",
    "-1 \"The number of columns in the initial dataset is: \",string count cols amzndaydata;\n",
    "-1 \"The number of columns in the unfiltered dataset is: \",string count cols tabraw;\n",
    "-1 \"The number of columns in the filtered dataset is: \",string count cols tabreduced;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data must now be converted to a matrix from a table in order to allow it to be passed to a machine learning algorithm for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mattab:{flip value flip x}\n",
    "fitvalsfilter:0^mattab[value tabreduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search is the process of finding optimal parameters for a given model. This works by applying a model to a dataset while also giving a dictionary with various parameters for the model. The gridserch applies various combinations of these parameters, as a results it returns the optimal parameters for the model along with the accuracy result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr:.p.import[`sklearn.ensemble][`:GradientBoostingRegressor]\n",
    "dict:`learning_rate`n_estimators`random_state!(0.1 0.3;200 400;l:1?1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the indices in ascending order of the dataset partitioned into k subsections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "i:.ml.xval.kfsplit[targets;3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1972137\n",
       "`learning_rate`n_estimators`random_state!(,0.1;,400;,205)\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".ml.xval.gridsearch[fitvalsfilter;targets;i;regr;dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from the grid search we can apply this to the Random Forest Classifier model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf:.p.import[`sklearn.ensemble][`:GradientBoostingRegressor\n",
    "    ][`learning_rate pykw 0.1;`n_estimators pykw 400;`random_state pykw first l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain-forward, Monte Carlo and Repeated Stratified Randomised k-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain forward is a useful cross validation technique when dealing with time series data. In time series cross validation, each day is set to be the test data, with all the days prior used as the training data.\n",
    "\n",
    "The Monte Carlo method involves randomly selecting a certain amount of the data, using the rest as the test set.  This process is then repeated a number of times, taking different random data as the training and testing set each time. \n",
    "\n",
    "In k-fold cross validation, the data is split up into k equal size sections. One fold is kept for validation while the other k-1 folds are used for training. The process is repeated k times so that each iteration a different fold is used as validation. Stratification is the process in which the dataset is arranged so that each fold has a good representation of the dataset. This is used xtensively in cases where the distribution of classes in the data is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation score using cross-forward is -0.6752342\n",
      "The cross validation score using monte-carlo is 0.9994306\n",
      "The cross validation score using repeated stratified randomized K-fold iss 0.9992382\n"
     ]
    }
   ],
   "source": [
    "chainfor:.ml.xval.chainxval[fitvalsfilter;targets;5;clf]\n",
    "montecarlo:.ml.xval.mcxval[fitvalsfilter;targets;.2;clf;3]\n",
    "repkf:.ml.xval.repkfstrat[fitvalsfilter;targets;3;4;clf]\n",
    "\n",
    "-1\"The cross validation score using cross-forward is \",string chainfor;\n",
    "-1\"The cross validation score using monte-carlo is \",string montecarlo;\n",
    "-1\"The cross validation score using repeated stratified randomized K-fold iss \",string repkf;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example it is evident that the Monte Carlo and Repeated Stratified Randomised k-fold method gives the most accurate results on this particular dataset. This shows how in this case, repeatedly splitting the input and target data at random leads to high cross validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
