{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and Time Series Forecasting in kdb+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate the use of feature extraction and selection in kdb+ as a tool for forecasting the future behaviour of a system. In this case we are using information about the historical behaviour of a stock with the goal of predicting the actual value of the stocks close price the next day.\n",
    "\n",
    "As is demonstrated in the results section of this notebook this should **not** be used as a method for stock prediction and is shown here as a use-case to demonstrate the versatility of the FRESH algorithm, its use outside of classification and when dealing with historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Library Scripts and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell the functions contained in the ML-Toolkit including both the FRESH algorithm and broader utility functions are loaded into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~\n"
     ]
    }
   ],
   "source": [
    "\\l ../../ml.q\n",
    ".ml.loadfile`:init.q\n",
    "\n",
    "\\c 15 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in a dataset containing the daily Open/Low/High/Close/open interest prices and Volume of trades for Amazon Stock from 1997-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       open high low  close volume   openint\n",
       "------------------------------------------------\n",
       "1997.05.16 1.97 1.98 1.71 1.73  14700000 0      \n",
       "1997.05.19 1.76 1.77 1.62 1.71  6106800  0      \n",
       "1997.05.20 1.73 1.75 1.64 1.64  5467200  0      \n",
       "1997.05.21 1.64 1.65 1.38 1.43  18853200 0      \n",
       "1997.05.22 1.44 1.45 1.31 1.4   11776800 0      \n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"This dataset contains stock information for 5170 days.\"\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "date       open high low  close volume  \n",
       "----------------------------------------\n",
       "1997.05.16 1.97 1.98 1.71 1.73  14700000\n",
       "1997.05.19 1.76 1.77 1.62 1.71  6106800 \n",
       "1997.05.20 1.73 1.75 1.64 1.64  5467200 \n",
       "1997.05.21 1.64 1.65 1.38 1.43  18853200\n",
       "1997.05.22 1.44 1.45 1.31 1.4   11776800\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5#amzndaydata:{lower[cols x]xcol x}(\"DFFFFJJ\";enlist \",\")0:`:SampleDatasets/amzn_day.us.txt\n",
    "-1!\"This dataset contains stock information for \",(string count amzndaydata),\" days.\"\n",
    "5#amzndaydata:.ml.dropconstant[amzndaydata] / drop columns without variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign extracted features and complete extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are attempting to use rolled table forecasting frames to predict the close price for the next day given extracted features from the previous 10 days. To generate the targets the first 10 days were omitted as these the rolled table frames in this case would be incomplete and as such may skew our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the target values for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabletargets:10 _amzndaydata\n",
    "targets:tabletargets[`close]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we produce polynomial features from our data in order to allow for interactions between terms in the system to also be studied not just the individual features. The date column is also removed from the data as this is not used as a feature and will not be required given the data will be subject to a sliding window which negates its significance as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open high low  close volume   open_high open_low open_close open_volume  high_low high_close high..\n",
       "-------------------------------------------------------------------------------------------------..\n",
       "1.97 1.98 1.71 1.73  14700000 3.9006    3.3687   3.4081     2.8959e+07   3.3858   3.4254     2.91..\n",
       "1.76 1.77 1.62 1.71  6106800  3.1152    2.8512   3.0096     1.074797e+07 2.8674   3.0267     1.08..\n",
       "1.73 1.75 1.64 1.64  5467200  3.0275    2.8372   2.8372     9458256      2.87     2.87       9567..\n",
       "1.64 1.65 1.38 1.43  18853200 2.706     2.2632   2.3452     3.091925e+07 2.277    2.3595     3.11..\n",
       "1.44 1.45 1.31 1.4   11776800 2.088     1.8864   2.016      1.695859e+07 1.8995   2.03       1.70..\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/ Add 2nd order polynomial features to the table \n",
    "table:amzndaydata^.ml.polytab[flip 1_flip amzndaydata;2]\n",
    "/ Remove the date column from the data as the rolling of data is independent of this\n",
    "5#table:(1_cols t)#t:table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing a rolling table forecasting frame from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function creates a rolling window with window lengths n on the data and implements feature extraction on each window. Caution should be exercised when applying this to large datasets as the number of calculations required will be;**\n",
    "```q\n",
    "(1+count table)-n\n",
    "```\n",
    "**It is here as an example of the use of rolling windows for feature forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollcreatefeatures:{[x;fns;n] \n",
    " raze{.ml.fresh.createfeatures[x;`placer;(-1)_cols x;y]}[;fns]each\n",
    " {update placer:last y from x y}[x;]each dropswin[n;til count x]}\n",
    "dropswin:{(-1) _ (x-1) _ swin[x;y]}\n",
    "swin:{[w;s]{1_x,y}\\[w#0;s]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f             | pnum pnames pvals valid\n",
      "--------------| -----------------------\n",
      "absenergy     | 0                 1    \n",
      "abssumchange  | 0                 1    \n",
      "count         | 0                 1    \n",
      "countabovemean| 0                 1    \n",
      "countbelowmean| 0                 1    \n",
      "firstmax      | 0                 1    \n",
      "firstmin      | 0                 1    \n",
      "hasdup        | 0                 1    \n",
      "hasdupmax     | 0                 1    \n",
      "hasdupmin     | 0                 1    \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show dict:.ml.fresh.params\n",
    "\n",
    "dict:update valid:0b from dict where f in `c3`numpeaks`quantile`fftcoeff`spktwelch`ratiobeyondsigma`augfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell produces features extracted from 10 day sliding windows over the data, these are used in the prediction of the following days close price. \n",
    "\n",
    "The keyed column in the output table gives the column number of the last value in each window. \n",
    "\n",
    "All incomplete windows have been removed from the application of the sliding window and the  window for the last day is not created as this could not be used in the prediction of a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlteam/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placer| open_absenergy open_abssumchange open_count open_countabovemean open_countbelowmean open_..\n",
      "------| -----------------------------------------------------------------------------------------..\n",
      "9     | 26.2488        0.89              10         5                   5                   0    ..\n",
      "10    | 24.648         0.69              10         4                   6                   0    ..\n",
      "11    | 23.8913        0.68              10         3                   7                   0    ..\n",
      "12    | 23.0888        0.64              10         4                   6                   0    ..\n",
      "13    | 22.4156        0.5               10         6                   4                   0.3  ..\n",
      "14    | 22.6524        0.57              10         6                   4                   0.2  ..\n",
      "15    | 23.4199        0.61              10         4                   6                   0.9  ..\n",
      "16    | 24.0639        0.55              10         3                   7                   0.9  ..\n",
      "17    | 23.9676        0.59              10         3                   7                   0.8  ..\n",
      "18    | 24.0924        0.56              10         4                   6                   0.7  ..\n",
      "..\n",
      "The forecasting frame contains 5160 datapoints.\n"
     ]
    }
   ],
   "source": [
    "show tabraw:rollcreatefeatures[table;dict;10]\n",
    "-1\"The forecasting frame contains \",(string count tabraw),\" datapoints.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature significance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placer| open_fftaggreg_skew open_fftaggreg_kurtosis high_fftaggreg_skew high_fftaggreg_kurtosis l..\n",
      "------| -----------------------------------------------------------------------------------------..\n",
      "9     | 3.34865             15.10603                3.338026            14.96626                4..\n",
      "10    | 4.738168            28.64043                4.732788            28.36683                 ..\n",
      "11    |                                                                                         4..\n",
      "12    | 4.460971            23.85714                4.471995            23.85924                 ..\n",
      "13    |                                                                                          ..\n",
      "14    |                                             4.749852            26.05558                4..\n",
      "15    | 4.738123            26.48774                                                            4..\n",
      "16    |                                                                                          ..\n",
      "17    |                                                                                          ..\n",
      "18    |                                             5.212446            32.16899                 ..\n",
      "..\n",
      "The number of columns in the initial dataset is: 6\n",
      "The number of columns in the unfiltered dataset is: 3361\n",
      "The number of columns in the filtered dataset is: 1411\n"
     ]
    }
   ],
   "source": [
    "show tabreduced:key[tabraw]!(.ml.fresh.significantfeatures[p;targets])#p:value tabraw\n",
    "-1 \"The number of columns in the initial dataset is: \",string count cols amzndaydata;\n",
    "-1 \"The number of columns in the unfiltered dataset is: \",string count cols tabraw;\n",
    "-1 \"The number of columns in the filtered dataset is: \",string count cols tabreduced;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data must now be converted to a matrix from a table in order to allow it to be passed to a machine learning algorithm for training.\n",
    "\n",
    "In the below cell, I have reintroduced the original data for each day into the dataset such that it now contains both the original and derived datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mattab:{flip value flip x}\n",
    "rawdata:-1 _9 _amzndaydata\n",
    "fitvalsfilter:0^mattab[rawdata,'value tabreduced]\n",
    "fitvalsraw:0^mattab[rawdata,'value tabraw]\n",
    "newpredictor:0^mattab[delete date from rawdata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train our model using a gradient boost regressor to estimate the close price. The application of forms of regression on financial data can be quite tempermental with high dependency on how the data is split influencing the final result achieved.\n",
    "\n",
    "In the definition of the gradient boosting regressor below the addition of``` `verbose pykw 1``` allows for the training times and training loss as a function of iterations to be displayed, this is omitted here as a means of ensuring the notebook is not cluttered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k:rand 1000\n",
    "reg:.p.import[`sklearn.ensemble][`:GradientBoostingRegressor][`learning_rate pykw 0.1;`n_estimators pykw 200;`random_state pykw k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to the models and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example:\n",
    "\n",
    "* dict1 = input only the initial time series data\n",
    "* dict2 = unfiltered data input.\n",
    "* dict3 = filtered data input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1:.ml.traintestsplit[newpredictor;targets;0.2];\n",
    "dict2:.ml.traintestsplit[fitvalsraw;targets;0.2];\n",
    "dict3:.ml.traintestsplit[fitvalsfilter;targets;0.2];\n",
    "\n",
    "reg[`:fit][dict1[`xtrain];dict1[`ytrain]]`;\n",
    "pred1:reg[`:predict][dict1[`xtest]]`\n",
    "\n",
    "reg[`:fit][dict2[`xtrain];dict2[`ytrain]]`;\n",
    "pred2:reg[`:predict][dict2[`xtest]]`\n",
    "\n",
    "reg[`:fit][dict3[`xtrain];dict3[`ytrain]]`;\n",
    "pred3:reg[`:predict][dict3[`xtest]]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Below the mean squared error is calculated between the predicted values of the next day close price and the actual value, this is a reasonable proxy for the accuracy of the model. The benchmark which we compare the model to is that todays close price is the best indicator of what tomorrows close will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1 \"The mean square error(mse) between the test and prediction from the untreated data is: \",string .ml.mse[dict1[`ytest];pred1];\n",
    "-1 \"The mse between the test and predicted data without filtering is: \",string .ml.mse[dict2[`ytest];pred2];\n",
    "-1 \"The mse between the test and predicted data with filtering is: \",string .ml.mse[dict3[`ytest];pred3];\n",
    "-1 \"The mse between the current and previous day would be: \",string .ml.mse . 1 -1_\\:amzndaydata[`close];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt:.p.import[`matplotlib]`:pyplot\n",
    "\n",
    "plt[`:close][]`;\n",
    "plt[`:figure][`figsize pykw (15 7.5)]`;\n",
    "plt[`:title][`$\"Next day close price prediction\"];\n",
    "plt[`:plot][dict2[`ytest];\"r\";`label pykw `$\"real value\"]`;\n",
    "plt[`:plot][pred2;\"k--\";`label pykw `$\"predicted value\"]`;\n",
    "plt[`:legend][]`;\n",
    "plt[`:xlim][200;300]`;\n",
    "plt[`:xlabel][\"Random predicted date\"];\n",
    "plt[`:ylabel][\"Close Price\"];\n",
    "plt[`:show][]`;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple runs of the above fit and results sections give an indication both of the usefulness of this form of analysis and the difficultly which is posed in the prediction of stock information. \n",
    "\n",
    "In the majority of cases it is seen that the mean squared error decreases in the order \n",
    "\n",
    "1. Untreated Data\n",
    "2. Extracted Features without significance testing\n",
    "3. Extracted Features with significance testing\n",
    "4. Yesterday's price = Today's price\n",
    "\n",
    "However depending on how the data is split by the traintestsplit function large variations in the the mean squared error can occur. This relates to the inclusion or omission of specific events which would cause large errors in prediction such as issues with the global economy or issues with staff. It can also have a detrimental effect on the order which is seen above with variations in this order possible if the features extracted from the split data are not truely indicative of the behaviour of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
